## COMP6651 - WINTER 2025 COURSE PROJECT

This repository contains the implementation, analysis, and experimentation of several well-known clustering algorithms as part of the **COMP 6651: Algorithm Design Techniques** course at Concordia University (Winter 2025).

## ğŸ“ Directory Structure

```
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ AI_index_db.csv
â”‚   â”œâ”€â”€ earthquakes_column_descriptors.txt
â”‚   â”œâ”€â”€ earthquakes.csv
â”‚   â””â”€â”€ iris.csv

â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01-dbscan.ipynb
â”‚   â”œâ”€â”€ 02-optics.ipynb
â”‚   â”œâ”€â”€ 03-gmm.ipynb
â”‚   â”œâ”€â”€ 04-kmeans.ipynb
â”‚   â”œâ”€â”€ 05-kmedoids.ipynb
â”‚   â”œâ”€â”€ 06-affinity.ipynb
â”‚   â”œâ”€â”€ 07-mean-shift.ipynb
â”‚   â”œâ”€â”€ 08-birch.ipynb
â”‚   â””â”€â”€ 09-agglomerative.ipynb
```


## ğŸ“Œ Project Objectives

The goal of this project is to:
- Understand, implement, and analyze the complexity of various clustering algorithms.
- Evaluate their performance using multiple metrics.
- Experiment with real-world datasets and compare custom implementations with Scikit-learn equivalents.

## ğŸ§  Implemented Clustering Algorithms

The following clustering techniques are implemented and analyzed:

- ğŸ“ˆ **k-means**
- ğŸ’ **k-medoids**
- ğŸ§  **Gaussian Mixture Model (GMM)**
- ğŸŒ **DBSCAN**
- ğŸ“ **OPTICS**
- ğŸŒ² **BIRCH**
- ğŸ’¬ **Affinity Propagation**
- ğŸ”„ **Mean Shift**
- ğŸ§© **Agglomerative Hierarchical Clustering**

## ğŸ“ Evaluation Metrics

All clustering algorithms are evaluated using the following metrics:
- Silhouette Score
- Davies-Bouldin Index
- Calinski-Harabasz Index (Variance Ratio Criterion)
- Adjusted Rand Index (ARI)
- Mutual Information (MI)
- Split
- Diameter

## ğŸ“Š Datasets Used

- **Iris Dataset**: [Kaggle Link](https://www.kaggle.com/datasets/himanshunakrani/iris-dataset)
- **AI Global Index Dataset**: [Kaggle Link](https://www.kaggle.com/datasets/katerynameleshenko/ai-index)
- **Global Earthquake Dataset**: [Kaggle Link](https://www.kaggle.com/datasets/shreyasur965/recent-earthquakes)

These datasets are stored in the `datasets/` directory and are used in Part II of the project.

## âš™ï¸ Features

- Feature scaling and dissimilarity coefficient computations (Euclidean, mixed types).
- Complexity analysis of each algorithm.
- Visual and statistical comparison with Scikit-learn implementations.
- Experimentation with feature selection and metric effectiveness.

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/gideonpeters/comp6651-project.git
   cd comp6651-project
   ```

2. Install dependencies (if applicable):
    ```bash
    pip install -r requirements.txt
    ```

3. Run algorithm scripts using .ipynb code blocks and in the right sequence.

4. View output and results in respective directories or generated plots.

## ğŸ“„ Reports
Detailed academic-style reports for Part I and Part II are provided (PDF format), discussing:

- Algorithm analysis and complexity
- Evaluation metrics and theoretical insights
- Experiments and comparative performance
- Team contributions and references

## ğŸ“œ Notes
- No input parameters are hardcoded; all data is read from input files.
- All AI-generated content (if any) will be disclosed clearly in the appendix sections of the reports.

## ğŸ‘¥ Team Contributions

| Team Member             | Contributions |
|-------------------------|----------------------------------------------------------------------------------------------------------------------------------|
| **Gideon Peters**        | - Literature review on clustering algorithms.<br>- Implemented k-means, k-medoids, and GMM algorithms.<br>- Conducted complexity analysis for centroid-based clustering methods.<br>- Wrote sections on k-means accuracy and improvements. |
| **Bhoomi**               | - Implemented DBSCAN, OPTICS, and Affinity Propagation.<br>- Conducted complexity analysis for density-based clustering methods.<br>- Analyzed clustering evaluation metrics and provided mathematical definitions.<br>- Wrote sections on metrics appropriateness. |
| **Anjolaoluwa Lasekan** | - Implemented hierarchical clustering (BIRCH, Agglomerative).<br>- Prepared experiments and dataset preprocessing.<br>- Evaluated results using silhouette score, Davies-Bouldin Index, and ARI.<br>- Compiled the final report and formatted the document in LaTeX. |
| **Masum Newaz**         | - Highlighted affinity propagation.<br>- Worked on mean shift clustering algorithm.<br>- Compiled the final report and formatted the document in LaTeX. |

> All team members contributed equally to discussions, debugging, and reviewing the report. The project was a collaborative effort, and responsibilities were distributed at random.


Feel free to fork, explore, and adapt this project to learn more about clustering techniques and algorithmic design in machine learning!